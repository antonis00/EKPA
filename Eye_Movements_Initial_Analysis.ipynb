{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPjMPcMIs/bFreaeefOZLvX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/antonis00/EKPA/blob/main/Eye_Movements_Initial_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Imports\n",
        "\n",
        "import os\n",
        "import re\n",
        "import pandas as pd\n",
        "import shutil\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.utils import to_categorical, plot_model\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import userdata"
      ],
      "metadata": {
        "id": "i6JuOHwF0ejU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "zLPN2pSLyiIB",
        "outputId": "e3307379-2e63-4b75-e98a-e7feef2b3028"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax (<ipython-input-1-4ffdac8e4dcf>, line 1)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-4ffdac8e4dcf>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    Remove prefix from file names\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ],
      "source": [
        "### Remove prefix from file names\n",
        "\n",
        "# Directory where the original files are located\n",
        "source_directory = r'C:\\Users\\apatergianakis\\Desktop\\Files\\Personal\\PhD\\DataSets\\Eye Movements\\data'\n",
        "\n",
        "# Directory where you want to save the new files\n",
        "destination_directory = r'C:\\Users\\apatergianakis\\Desktop\\Files\\Personal\\PhD\\DataSets\\Eye Movements\\data\\renamed'\n",
        "\n",
        "# Ensure the destination directory exists\n",
        "if not os.path.exists(destination_directory):\n",
        "    os.makedirs(destination_directory)\n",
        "\n",
        "# List all files in the source directory\n",
        "file_list = os.listdir(source_directory)\n",
        "\n",
        "# Loop through all files in the list\n",
        "for file_name in file_list:\n",
        "    # Check if the file is a CSV by extension and is not a directory\n",
        "    if file_name.lower().endswith('.csv') and os.path.isfile(os.path.join(source_directory, file_name)):\n",
        "        # Remove the 'S_' and the first digit following it\n",
        "        new_name = re.sub(r'S_\\d', '', file_name)\n",
        "        # The complete path for the new file\n",
        "        new_file_path = os.path.join(destination_directory, new_name)\n",
        "        # The complete path for the old file\n",
        "        old_file_path = os.path.join(source_directory, file_name)\n",
        "        # Copy the file to the new name\n",
        "        shutil.copy2(old_file_path, new_file_path)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Add new column with the label\n",
        "# Directory with the original CSV files\n",
        "source_directory = r'C:\\Users\\apatergianakis\\Desktop\\Files\\Personal\\PhD\\DataSets\\Eye Movements\\data\\renamed'\n",
        "\n",
        "# Directory where the new labeled files will be stored\n",
        "destination_directory = os.path.join(source_directory, 'labeled')\n",
        "\n",
        "# Ensure the destination directory exists\n",
        "if not os.path.exists(destination_directory):\n",
        "    os.makedirs(destination_directory)\n",
        "\n",
        "# Iterate over all files in the source directory\n",
        "for filename in os.listdir(source_directory):\n",
        "    if filename.endswith('.csv'):\n",
        "        # Extract the participant ID from the filename\n",
        "        participant_id = re.match(r'^(\\d+)_', filename).group(1)\n",
        "\n",
        "        # Construct the full file paths\n",
        "        src_file_path = os.path.join(source_directory, filename)\n",
        "        dest_file_path = os.path.join(destination_directory, filename)\n",
        "\n",
        "        # Read the CSV file into a DataFrame\n",
        "        df = pd.read_csv(src_file_path)\n",
        "\n",
        "        # Add the participant_id column\n",
        "        df['participant_id'] = participant_id\n",
        "\n",
        "        # Save the modified DataFrame to the new location\n",
        "        df.to_csv(dest_file_path, index=False)"
      ],
      "metadata": {
        "id": "KI6sbdP2yzi7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WnJCjhgTzEO2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Copy vid files only to a different folder\n",
        "\n",
        "# Define the source and destination directories\n",
        "source_directory = r'C:\\Users\\apatergianakis\\Desktop\\Files\\Personal\\PhD\\DataSets\\Eye Movements\\data\\renamed\\labeled'\n",
        "destination_directory = r'C:\\Users\\apatergianakis\\Desktop\\Files\\Personal\\PhD\\DataSets\\Eye Movements\\data\\renamed\\labeled\\vid'\n",
        "\n",
        "# Create the destination directory if it does not exist\n",
        "if not os.path.exists(destination_directory):\n",
        "    os.makedirs(destination_directory)\n",
        "\n",
        "# Copy each CSV file that contains 'VID' in its name to the new subfolder\n",
        "for filename in os.listdir(source_directory):\n",
        "    if filename.endswith('.csv') and 'VID' in filename:\n",
        "        # Construct full file paths\n",
        "        src_file_path = os.path.join(source_directory, filename)\n",
        "        dest_file_path = os.path.join(destination_directory, filename)\n",
        "\n",
        "        # Copy the file\n",
        "        shutil.copy2(src_file_path, dest_file_path)\n"
      ],
      "metadata": {
        "id": "ZN9kCetZzKxi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Merge csv files to a single file\n",
        "\n",
        "# Directory with the CSV files to merge\n",
        "source_directory = r'C:\\Users\\apatergianakis\\Desktop\\Files\\Personal\\PhD\\DataSets\\Eye Movements\\data\\renamed\\labeled\\vid'\n",
        "\n",
        "# Directory where the merged file will be stored\n",
        "destination_directory = os.path.join(source_directory, 'one')\n",
        "\n",
        "# Ensure the destination directory exists\n",
        "if not os.path.exists(destination_directory):\n",
        "    os.makedirs(destination_directory)\n",
        "\n",
        "# List to hold data from each CSV file\n",
        "data_frames = []\n",
        "\n",
        "# Iterate over all files in the source directory\n",
        "for filename in os.listdir(source_directory):\n",
        "    if filename.endswith('.csv'):\n",
        "        # Construct the full file path\n",
        "        file_path = os.path.join(source_directory, filename)\n",
        "\n",
        "        # Read the CSV file into a DataFrame\n",
        "        df = pd.read_csv(file_path)\n",
        "\n",
        "        # Append the DataFrame to the list\n",
        "        data_frames.append(df)\n",
        "\n",
        "# Concatenate all the data frames in the list\n",
        "merged_df = pd.concat(data_frames, ignore_index=True)\n",
        "\n",
        "# Path for the merged file\n",
        "merged_file_path = os.path.join(destination_directory, 'merged.csv')\n",
        "\n",
        "# Save the merged DataFrame to CSV\n",
        "merged_df.to_csv(merged_file_path, index=False)\n"
      ],
      "metadata": {
        "id": "WlxkAv8mzKpW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Count the participants from the merged file\n",
        "\n",
        "# Path to the merged CSV file\n",
        "merged_file_path = r'C:\\Users\\apatergianakis\\Desktop\\Files\\Personal\\PhD\\DataSets\\Eye Movements\\data\\renamed\\labeled\\vid\\one\\merged.csv'\n",
        "\n",
        "# Check if the merged file exists\n",
        "if os.path.exists(merged_file_path):\n",
        "    # Read the CSV file into a DataFrame\n",
        "    df = pd.read_csv(merged_file_path)\n",
        "\n",
        "    # Count the number of unique participant IDs\n",
        "    unique_participants = df['participant_id'].nunique()\n",
        "\n",
        "    print(f'There are {unique_participants} unique participants.')\n",
        "else:\n",
        "    print(f'The file {merged_file_path} does not exist.')\n"
      ],
      "metadata": {
        "id": "8IM4sV-S0DyN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "df = pd.read_csv('/content/merged.csv')\n",
        "# userdata.get('secretName') use secret"
      ],
      "metadata": {
        "id": "VwnZY-Dv0mK6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming the DataFrame 'df' is already loaded with the eye-tracking data\n",
        "features = ['x', 'y', 'lx', 'ly', 'rx', 'ry', 'clx', 'cly', 'clz', 'crx', 'cry', 'crz']\n",
        "target = 'participant_id'"
      ],
      "metadata": {
        "id": "syOaNSUr07-r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Separate features and target\n",
        "X = df[features]\n",
        "y = df[target]"
      ],
      "metadata": {
        "id": "wZIgCnyG09a7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert labels to categorical one-hot encoding\n",
        "num_classes = 407  # You have 407 participants\n",
        "y_one_hot = to_categorical(y, num_classes=num_classes)"
      ],
      "metadata": {
        "id": "uyi5knYi1Ap_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize feature values\n",
        "scaler = StandardScaler()\n",
        "X_normalized = scaler.fit_transform(X)"
      ],
      "metadata": {
        "id": "dAdtiCAd1BGe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_normalized, y_one_hot, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "A1MwhbD91Gh2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build a simple neural network model\n",
        "model = Sequential()\n",
        "model.add(Dense(128, input_dim=len(features), activation='relu'))\n",
        "model.add(Dropout(0.5))  # Dropout layer to prevent overfitting\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes, activation='softmax'))  # Output layer for 407 participants"
      ],
      "metadata": {
        "id": "If5loV761IRW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the depp learning model to an image\n",
        "plot_model(model, to_file='model.png', show_shapes=True, show_layer_names=True)"
      ],
      "metadata": {
        "id": "46qMdVFe1MRC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the image of the model\n",
        "from IPython.display import Image\n",
        "Image(filename='model.png')"
      ],
      "metadata": {
        "id": "TYdIZoHF1NeD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model.compile(loss='categorical_crossentropy',  # Use categorical_crossentropy for multi-class problems\n",
        "              optimizer=Adam(learning_rate=0.001),\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "nxWWrms91OnO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=100, batch_size=32)"
      ],
      "metadata": {
        "id": "k31CE3781TrL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "evaluation = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(f'Test Loss: {evaluation[0]}')\n",
        "print(f'Test Accuracy: {evaluation[1]}')"
      ],
      "metadata": {
        "id": "HiSxB08L1Vkf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot training & validation accuracy values\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')"
      ],
      "metadata": {
        "id": "QGeCJ7LG1XHT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot training & validation loss values\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')"
      ],
      "metadata": {
        "id": "VEx0sCrW1Xpj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "WUXuag-71ZdI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}